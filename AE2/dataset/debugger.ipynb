{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/l/vision/zekrom_ssd/fraramir/miniconda3/envs/torch-gpu/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import json\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GTEA_FRAMES():\n",
    "    def __init__(self,\n",
    "                 root='/nfs/wattrel/data/md0/datasets/action_seg_datasets/GTEA',\n",
    "                 small_test=False,\n",
    "                 frame_dir='/nfs/wattrel/data/md0/datasets/action_seg_datasets/GTEA/frames/',\n",
    "                 save_feat_dir='gtea_vit_features',\n",
    "                 transform=None,\n",
    "                 sliding_window=15):\n",
    "        self.root = root\n",
    "        self.small_test = small_test\n",
    "        self.frame_dir = frame_dir\n",
    "        self.save_feat_dir = save_feat_dir\n",
    "        self.transform = transform\n",
    "        self.sliding_window = sliding_window\n",
    "        all_files = os.walk(self.frame_dir)\n",
    "        self.convert_tensor = transforms.ToTensor()\n",
    "        self.data_lst = []\n",
    "        for path, dir, filelst in all_files:\n",
    "            if len(filelst) > 0:\n",
    "                self.data_lst.append((filelst, path))\n",
    "\n",
    "    def get_it(self, index):\n",
    "        # window_size = self.sliding_window\n",
    "        videoname = self.data_lst[index]\n",
    "        vroot = videoname[1]\n",
    "        path_list = videoname[0]\n",
    "        # vlen = len(path_list)\n",
    "        path_list.sort(key=lambda x: int(x[4:-4]))\n",
    "        # seq = [Image.open(os.path.join(vroot, p)).convert('RGB') for p in path_list]\n",
    "\n",
    "        # if self.sliding_window:\n",
    "        #     first_frame = seq[0]\n",
    "        #     last_frame = seq[-1]\n",
    "        #     seq = [first_frame] * ((self.sliding_window-1)//2) + seq + [last_frame] * ((self.sliding_window-1)//2)\n",
    "\n",
    "        # if self.transform is not None:\n",
    "        #     seq = self.transform(seq)\n",
    "        # else:\n",
    "        #     convert_tensor = transforms.ToTensor()\n",
    "        #     seq = [convert_tensor(img) for img in seq]\n",
    "        #     seq = torch.stack(seq)\n",
    "        vsplt = vroot.split('/')[-1]\n",
    "        fname = vsplt + '.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = GTEA_FRAMES()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(xx.data_lst)# xx.get_it(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "root='/nfs/wattrel/data/md0/kung/state-aware-video-pretrain/data/breakfast'\n",
    "data_lst = np.load(\n",
    "            os.path.join(root, 'splits', 'breakfast_exfm.npy'))\n",
    "frame_dir='/nfs/wattrel/data/md0/datasets/action_seg_datasets/breakfast/frames/'\n",
    "num_frames= 15\n",
    "def frame_sampler(videoname, vlen):\n",
    "        start_idx = int(videoname[1])\n",
    "        seq_idx = np.arange(num_frames) + start_idx\n",
    "        print(\"seq_idx \", seq_idx)\n",
    "        seq_idx = np.where(seq_idx < vlen, seq_idx, vlen - 1)\n",
    "        return seq_idx\n",
    "\n",
    "def get_it(index):\n",
    "    videoname = data_lst[index]\n",
    "    print(\"videoname \", videoname)\n",
    "    vroot = videoname[0]\n",
    "    vsplt = vroot.split('_', 2)\n",
    "    print(\"vroot \", vroot)\n",
    "    print(\"vsplt \", vsplt)\n",
    "\n",
    "    vname_splt = np.copy(vsplt)\n",
    "    if vsplt[1] == 'stereo':\n",
    "        vname_splt[1] = 'stereo01'\n",
    "        vname_splt[2] = vsplt[2][:-4]\n",
    "    vpath = os.path.join(frame_dir, *vsplt)\n",
    "    vlen = len([f for f in os.listdir(vpath) if os.path.isfile(os.path.join(vpath, f))])\n",
    "    path_list = os.listdir(vpath)\n",
    "    print(\"vpath \", vpath)\n",
    "    print(\"vlen \", vlen)\n",
    "    path_list.sort(key=lambda x: int(x[4:-4]))\n",
    "    frame_index = frame_sampler(videoname, vlen)\n",
    "    print(\"frame_index \", frame_index)\n",
    "    seq = [Image.open(os.path.join(vpath, path_list[i])).convert('RGB') for i in frame_index]\n",
    "    print(\"seq \", len(seq))\n",
    "    if 1:\n",
    "        convert_tensor = transforms.ToTensor()\n",
    "        seq = [convert_tensor(img) for img in seq]\n",
    "        seq = torch.stack(seq)\n",
    "    fname = vname_splt[0] + '_' + vname_splt[1] + '_' + vname_splt[2] + '_' + videoname[1] + '.npy'\n",
    "    print(\"fname \", fname)\n",
    "    return seq, fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "videoname  ['P03_cam01_P03_friedegg' '2048']\n",
      "vroot  P03_cam01_P03_friedegg\n",
      "vsplt  ['P03', 'cam01', 'P03_friedegg']\n",
      "vpath  /nfs/wattrel/data/md0/datasets/action_seg_datasets/breakfast/frames/P03/cam01/P03_friedegg\n",
      "vlen  4268\n",
      "seq_idx  [2048 2049 2050 2051 2052 2053 2054 2055 2056 2057 2058 2059 2060 2061\n",
      " 2062]\n",
      "frame_index  [2048 2049 2050 2051 2052 2053 2054 2055 2056 2057 2058 2059 2060 2061\n",
      " 2062]\n",
      "seq  15\n",
      "fname  P03_cam01_P03_friedegg_2048.npy\n"
     ]
    }
   ],
   "source": [
    "x,y = get_it(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(os.path.join(\"/nfs/wattrel/data/md0/datasets/AE2/AE2_data/tennis_forehand\", 'label.pickle'), 'rb') as handle:\n",
    "            dircy = pickle.load(handle)\n",
    "print(dircy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_frames_folders(parent_dir):\n",
    "    \"\"\"Recursively find all folders ending with '_frames' and print their paths.\"\"\"\n",
    "    for root, dirs, files in os.walk(parent_dir):\n",
    "        for d in dirs:\n",
    "            if d.endswith(\"_frames\"):\n",
    "                full_path = os.path.join(root, d)\n",
    "                print(full_path)\n",
    "\n",
    "def percent_folders_with_few_images(parent_dir, threshold):\n",
    "    \"\"\"Print the percentage of '_frames' folders that have less than `threshold` images.\"\"\"\n",
    "    total_folders = 0\n",
    "    folders_below_threshold = 0\n",
    "    all_paths = []\n",
    "    for root, dirs, files in os.walk(parent_dir):\n",
    "        for d in dirs:\n",
    "            if d.endswith(\"_frames\"):\n",
    "                total_folders += 1\n",
    "                full_path = os.path.join(root, d)\n",
    "                \n",
    "                image_count = sum(\n",
    "                    1 for f in os.listdir(full_path)\n",
    "                    if f.lower().endswith(('.jpg'))\n",
    "                )\n",
    "\n",
    "                if image_count < threshold:\n",
    "                    folders_below_threshold += 1\n",
    "                \n",
    "                all_paths.append([str(full_path), str(image_count)])\n",
    "                # else:\n",
    "                # for j in range(0,image_count, 16):\n",
    "                #     all_paths.append([str(full_path), str(j), str(image_count)])\n",
    "\n",
    "    if total_folders == 0:\n",
    "        print(\"No '_frames' folders found.\")\n",
    "    else:\n",
    "        percentage = (folders_below_threshold / total_folders) * 100\n",
    "        print(f\"{folders_below_threshold} out of {total_folders} folders have less than {threshold} images.\")\n",
    "        print(f\"That's {percentage:.2f}%.\")\n",
    "    \n",
    "    return all_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 out of 782 folders have less than 16 images.\n",
      "That's 1.15%.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parent_directory = \"/nfs/wattrel/data/md0/datasets/AE2/AE2_data\"\n",
    "# for root, dirs, files in os.walk(parent_directory):\n",
    "#     print(root)\n",
    "#     print(dirs)\n",
    "#     print(files)\n",
    "#     print('-'*20)\n",
    "# find_frames_folders(parent_directory)\n",
    "paths = percent_folders_with_few_images(parent_directory, 16)\n",
    "\n",
    "np.save(\"/nfs/wattrel/data/md0/datasets/AE2/AE2_metadata\", np.array(paths), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/wattrel/data/md0/datasets/AE2/AE2_data/pour_milk/test/ego/subject3_o1_1_cam4.npy\n",
      "subject3_o1_1_cam4_frames\n"
     ]
    }
   ],
   "source": [
    "data_lst = np.load(\n",
    "            \"/nfs/wattrel/data/md0/datasets/AE2/AE2_metadata.npy\")\n",
    "# print(os.listdir(data_lst[0][0]))\n",
    "print(data_lst[0][0][:-7] + '.npy')\n",
    "print(data_lst[0][0].split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00018\n"
     ]
    }
   ],
   "source": [
    "x = \"img_00018.jpg\"\n",
    "print(x[4:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['P03_cam01_P03_cereals' '0']\n",
      " ['P03_cam01_P03_cereals' '32']\n",
      " ['P03_cam01_P03_cereals' '64']\n",
      " ...\n",
      " ['P54_webcam02_P54_tea' '896']\n",
      " ['P54_webcam02_P54_tea' '928']\n",
      " ['P54_webcam02_P54_tea' '960']]\n"
     ]
    }
   ],
   "source": [
    "root='/nfs/wattrel/data/md0/kung/state-aware-video-pretrain/data/breakfast'\n",
    "data_lst = np.load(\n",
    "            os.path.join(root, 'splits', 'breakfast_exfm.npy'))\n",
    "print(data_lst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
